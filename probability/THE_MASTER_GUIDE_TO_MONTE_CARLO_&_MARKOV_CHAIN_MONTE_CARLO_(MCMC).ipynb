{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# THE MASTER GUIDE TO MONTE CARLO & MARKOV CHAIN MONTE CARLO (MCMC)\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Before Anything: The Core Idea of Monte Carlo\n",
        "\n",
        "The term **Monte Carlo** refers to using randomness to solve problems that are deterministic but too hard to solve analytically.\n",
        "\n",
        "Examples:\n",
        "\n",
        "- Estimating $$\\pi$$ by randomly throwing darts  \n",
        "- Approximating integrals in high dimensions  \n",
        "- Estimating probabilities when exact formulas are impossible  \n",
        "\n",
        "The basic philosophy:\n",
        "\n",
        "**If you can't compute it directly, simulate it.**\n",
        "\n",
        "This led to:\n",
        "\n",
        "- Monte Carlo integration  \n",
        "- Random sampling  \n",
        "- Stochastic optimization  \n",
        "- And eventually…  \n",
        "  **Markov Chain Monte Carlo (MCMC)**\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Why Do We Need MCMC? (The Pain of High Dimensions)\n",
        "\n",
        "Suppose you want to sample from a complicated probability distribution:\n",
        "\n",
        "$$\n",
        "p(x) \\propto f(x)\n",
        "$$\n",
        "\n",
        "But you **cannot compute the normalizing constant**:\n",
        "\n",
        "$$\n",
        "Z = \\int f(x) \\, dx\n",
        "$$\n",
        "\n",
        "This situation appears constantly in:\n",
        "\n",
        "- Bayesian inference  \n",
        "- High-dimensional probability  \n",
        "- Statistical physics  \n",
        "- Deep generative models  \n",
        "\n",
        "**Direct sampling is impossible.**\n",
        "\n",
        "Enter **MCMC**.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. What Is Markov Chain Monte Carlo (MCMC)?\n",
        "\n",
        "MCMC is a Monte Carlo method where:\n",
        "\n",
        "1. You build a **Markov chain**.  \n",
        "2. The chain is designed so its **stationary distribution equals the target distribution**.  \n",
        "3. You run the chain long enough.  \n",
        "4. You collect samples from it.\n",
        "\n",
        "Thus the chain “walks” through the space, and the long-run distribution of visited points approximates:\n",
        "\n",
        "$$\n",
        "p(x)\n",
        "$$\n",
        "\n",
        "So, MCMC samples from distributions you **cannot** sample from directly.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. The Intuition (Why It Works)\n",
        "\n",
        "Instead of generating **independent samples** from $$p(x)$$ — which is impossible —  \n",
        "MCMC generates **dependent samples** through a Markov chain.\n",
        "\n",
        "Imagine a drunk man walking across a landscape of hills and valleys.\n",
        "\n",
        "- Heights = probability density  \n",
        "- Higher regions = more likely values  \n",
        "- The walker wanders, moving uphill more often  \n",
        "- Sometimes moves downhill so he doesn’t get stuck  \n",
        "\n",
        "Over time, the walker spends more time in **high-probability regions**.\n",
        "\n",
        "Thus, the chain produces samples distributed according to:\n",
        "\n",
        "$$\n",
        "p(x)\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## 5. The Structure: What Every MCMC Algorithm Contains\n",
        "\n",
        "Every MCMC algorithm includes:\n",
        "\n",
        "- A target distribution $$p(x)$$  \n",
        "- A Markov chain with stationary distribution $$p(x)$$  \n",
        "- A transition mechanism  \n",
        "- A sampling process  \n",
        "- Burn-in (discard early samples)  \n",
        "- Optional thinning (reduce correlation)  \n",
        "\n",
        "The key idea:\n",
        "\n",
        "**If the chain is designed correctly, it converges to the target distribution.**\n",
        "\n",
        "---\n",
        "\n",
        "## 6. The Metropolis–Hastings Algorithm (The King of MCMC)\n",
        "\n",
        "The most influential MCMC algorithm ever developed.\n",
        "\n",
        "---\n",
        "\n",
        "### 6.1 Algorithm Steps\n",
        "\n",
        "1. Start at some point:\n",
        "\n",
        "   $$\n",
        "   x_0\n",
        "   $$\n",
        "\n",
        "2. Propose a new point:\n",
        "\n",
        "   $$\n",
        "   x' \\sim q(x' \\mid x)\n",
        "   $$\n",
        "\n",
        "3. Compute acceptance ratio:\n",
        "\n",
        "   $$\n",
        "   \\alpha = \\min \\left( 1,\\,\n",
        "   \\frac{p(x') q(x \\mid x')}{p(x) q(x' \\mid x)}\n",
        "   \\right)\n",
        "   $$\n",
        "\n",
        "4. Accept with probability $$\\alpha$$:\n",
        "\n",
        "   - If accepted → move to $$x'$$  \n",
        "   - If rejected → stay at $$x$$  \n",
        "\n",
        "You generate a chain:\n",
        "\n",
        "$$\n",
        "x_1, x_2, x_3, \\dots\n",
        "$$\n",
        "\n",
        "which converges toward sampling from:\n",
        "\n",
        "$$\n",
        "p(x)\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Special Case: Metropolis Algorithm\n",
        "\n",
        "If the proposal distribution is **symmetric**, i.e.,\n",
        "\n",
        "$$\n",
        "q(x' \\mid x) = q(x \\mid x')\n",
        "$$\n",
        "\n",
        "Then the acceptance rule simplifies beautifully:\n",
        "\n",
        "$$\n",
        "\\alpha = \\min \\left( 1,\\, \\frac{p(x')}{p(x)} \\right)\n",
        "$$\n",
        "\n",
        "This simplicity made the Metropolis algorithm historically important.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Gibbs Sampling (Another MCMC Giant)\n",
        "\n",
        "Used when you can sample from **conditional distributions**.\n",
        "\n",
        "Suppose:\n",
        "\n",
        "$$\n",
        "p(x, y)\n",
        "$$\n",
        "\n",
        "is hard to sample jointly.\n",
        "\n",
        "But you can sample:\n",
        "\n",
        "- $$x \\mid y$$  \n",
        "- $$y \\mid x$$  \n",
        "\n",
        "Then the Gibbs cycle is:\n",
        "\n",
        "$$\n",
        "x^{(t+1)} \\sim p(x \\mid y^{(t)})\n",
        "$$\n",
        "\n",
        "$$\n",
        "y^{(t+1)} \\sim p(y \\mid x^{(t+1)})\n",
        "$$\n",
        "\n",
        "Repeating this generates a Markov chain converging to the joint distribution:\n",
        "\n",
        "$$\n",
        "p(x, y)\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Why MCMC Works (Mathematical Foundation)\n",
        "\n",
        "The Markov chain must satisfy:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Irreducibility\n",
        "\n",
        "The chain can eventually reach **any region** of the distribution.\n",
        "\n",
        "### 2. Aperiodicity\n",
        "\n",
        "The chain does not get stuck in strict cycles.\n",
        "\n",
        "### 3. Detailed Balance\n",
        "\n",
        "$$\n",
        "p(x) P(x \\to x') = p(x') P(x' \\to x)\n",
        "$$\n",
        "\n",
        "This ensures $$p(x)$$ is a stationary distribution of the chain.\n",
        "\n",
        "### 4. Ergodicity\n",
        "\n",
        "Long-run averages converge to expectations under $$p(x)$$.\n",
        "\n",
        "These conditions make MCMC converge.\n",
        "\n",
        "---\n",
        "\n",
        "## 10. A Creative Example (Perfect for Beginners)\n",
        "\n",
        "Suppose you want to sample from:\n",
        "\n",
        "$$\n",
        "p(x) \\propto e^{-x^2/2}\n",
        "$$\n",
        "\n",
        "A Gaussian distribution — but we pretend we cannot sample from it directly.\n",
        "\n",
        "Use **Metropolis Algorithm**:\n",
        "\n",
        "1. Start at:\n",
        "\n",
        "   $$\n",
        "   x_0 = 0\n",
        "   $$\n",
        "\n",
        "2. Propose:\n",
        "\n",
        "   $$\n",
        "   x' = x + \\epsilon, \\quad \\epsilon \\sim N(0, 1)\n",
        "   $$\n",
        "\n",
        "3. Acceptance probability:\n",
        "\n",
        "   $$\n",
        "   \\alpha = \\min \\left( 1,\\,\n",
        "   e^{-(x'^2 - x^2)/2}\n",
        "   \\right)\n",
        "   $$\n",
        "\n",
        "4. Accept or reject.\n",
        "\n",
        "5. Repeat many times.\n",
        "\n",
        "After **burn-in**, the histogram of samples will match the true Gaussian curve.\n",
        "\n",
        "You sampled from a distribution **without ever computing its normalization constant**.\n",
        "\n",
        "That is the power of MCMC.\n",
        "\n",
        "---\n",
        "\n",
        "## 11. Where MCMC Is Used Today (Everywhere)\n",
        "\n",
        "### Bayesian statistics\n",
        "\n",
        "- Posterior sampling  \n",
        "- Hierarchical models  \n",
        "- Bayesian neural networks  \n",
        "\n",
        "### Machine learning\n",
        "\n",
        "- Generative modeling  \n",
        "- Energy-based models  \n",
        "- Variational inference comparison  \n",
        "\n",
        "### Physics\n",
        "\n",
        "- Ising model  \n",
        "- Molecular dynamics  \n",
        "- Thermodynamics  \n",
        "\n",
        "### Computational biology\n",
        "\n",
        "- Protein folding  \n",
        "- DNA sequence modeling  \n",
        "\n",
        "### Finance\n",
        "\n",
        "- Stochastic volatility models  \n",
        "- Risk estimation  \n",
        "\n",
        "### Deep Learning (Diffusion Models)\n",
        "\n",
        "Diffusion sampling noise steps can be viewed as a modern stochastic chain related to MCMC principles.\n",
        "\n",
        "---\n",
        "\n",
        "## 12. The Perfect Summary\n",
        "\n",
        "Monte Carlo → solve problems by random sampling.\n",
        "\n",
        "MCMC → sample from hard distributions by creating a Markov chain whose stationary distribution is the target.\n",
        "\n",
        "Metropolis–Hastings → general acceptance–rejection framework.\n",
        "\n",
        "Gibbs Sampling → sample conditionals when they are available.\n",
        "\n",
        "MCMC is essential for **Bayesian inference** and **modern probabilistic modeling**.\n",
        "\n",
        "In two lines:\n",
        "\n",
        "**Monte Carlo = simulate randomness.**  \n",
        "**MCMC = simulate a Markov chain that wanders through complex distributions and learns their shape.**\n"
      ],
      "metadata": {
        "id": "1P5wraDSwDgV"
      }
    }
  ]
}